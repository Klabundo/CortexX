services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./memory:/app/memory
      - ./storage:/app/storage
    restart: unless-stopped

  frontend:
    build: ./frontend
    ports:
      - "5173:5173"   # Nicht 3000, sondern Vite-Standard
    volumes:
      - ./frontend:/app:cached
      - /app/node_modules
    restart: unless-stopped

  vllm:
    image: vllm/vllm-openai:latest
    ports:
      - "8001:8000"
    volumes:
      - ./vllm/models/Qwen2-7B:/models/Qwen2-7B
    command: >
      python3 -m vllm.entrypoints.openai.api_server
      --model /models/Qwen2-7B
      --tokenizer /models/Qwen2-7B
      --port 8000
      --trust-remote-code
      --dtype auto
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    restart: unless-stopped

networks:
  default:
    driver: bridge
